# All-in-One 高并发智能编排器

这是一个专为计算密集型和API密集型任务设计的、功能完备的多进程并发处理器。它将一个复杂的、基于Google Gemini API的LaTeX文档渲染逻辑，与一个高级的、健壮的并发调度系统完美融合在了一个单一的Python文件中。

## 核心功能

*   **高并发处理**: 可配置同时运行的总进程数（默认为40），充分利用多核CPU和多API Key的优势。
*   **平滑启动机制**: 独创的、带延迟的进程创建循环，避免因一次性启动大量进程而导致的系统崩溃（“资源风暴”）。
*   **智能任务调度**: 基于效能评分的动态调度系统，综合考虑每个API Key的即时负载和长期压力，将新任务优先分配给最空闲的Key，实现“能者多劳”，最大化整体效率。
*   **终极状态检测**: 通过直接检查**原始PDF**是否已被成功复制到最终输出目录，来判断任务是否**完全成功**。这是最可靠的去重方法，完美解决了因失败重试而留下旧产物导致的逻辑漏洞。
*   **一体化设计**: 将所有业务逻辑和并发控制逻辑整合到单个文件中，无需维护多个脚本，易于理解、部署和修改。
*   **详细的彩色日志**: 通过精巧的异常处理链，实现了清晰的终端输出，让您对每个任务的成功、失败或异常一目了然。

---

## 我们的探索之旅：遇到的问题与解决方案

本脚本的最终形态，是解决了一系列实际工程问题的成果。了解这个过程，能更好地理解其设计哲学。

#### 1. 问题：启动时崩溃 (`[WinError 1455] 页面文件太小`)
*   **现象**: 当尝试使用 `multiprocessing.Pool` 一次性启动40个进程时，会瞬间产生巨大的系统资源请求，导致操作系统不堪重负而崩溃。
*   **解决方案**: 我们放弃了 `Pool`，转而使用更底层的 `multiprocessing.Process`。在主循环中，我们**逐个创建**进程，并在每创建一个新进程后，使用 `time.sleep()` 加入一个**短暂的延迟**。这将瞬间的资源风暴分散成了一系列操作系统可以轻松处理的平滑请求。

#### 2. 问题：API性能不均导致效率低下
*   **现象**: 简单地将任务轮流分配给不同的API Key，无法考虑到某些Key可能因网络或账户原因响应更快，导致“快者闲，慢者忙”，拖慢整体进度。
*   **解决方案**: 引入了**智能任务调度系统**。在分配新任务时，它会为每个可用的API Key计算一个“繁忙分数”（基于当前活跃任务数和名下剩余总任务数），并总能将新任务分配给得分最低（最不忙）的Key，实现真正的动态负载均衡。

#### 3. 问题：网络不稳定导致连接中断 (`EOF occurred`)
*   **现象**: 在中国大陆的网络环境下，即使使用高质量的代理线路（如IPLC），长时间的HTTPS连接（如上传大PDF文件）也可能被中间网络设备（如GFW）干扰而异常中断。
*   **解决方案的探讨**:
    *   **更换客户端**: 我们分析了Clash, Sing-box, V2Ray等客户端，结论是问题不在于客户端（“车”），而在于线路和协议（“路”）。
    *   **优化协议**: 我们认识到，需要使用能更好伪装流量的现代协议（如 **VLESS+Reality**）来从根本上避免被干扰。
    *   **优化网络参数**: 我们发现将网络接口的**MTU（最大传输单元）** 从默认的1500调整为更保守的**1420**，可以有效避免数据包在复杂网络路径中被分片，从而大大提高连接的稳定性。

#### 4. 问题：任务成功状态检测不可靠
*   **现象 (Bug V1.0)**: 最初检查 `generated.pdf` 的方法存在漏洞。如果一次失败的编译留下了一个**旧的、成功的**`generated.pdf`，任务会在下次运行时被错误地跳过，导致失败的任务永远无法被重试。
*   **解决方案 (终极版)**: 我们将成功标记改为检查**【原始PDF】**是否已被成功复制到最终输出目录。因为这个复制操作是整个成功流程的**最后一步**（在API调用、`.tex`生成、两次`xelatex`编译都成功之后），所以这是判断任务是否**完全成功**的最可靠标志。

---

## 系统要求

*   Python 3.7+
*   一个有效的LaTeX发行版（如 MiKTeX, TeX Live, MacTeX），并确保 `xelatex` 命令在系统的PATH中。
*   所需的Python库:
    ```bash
    pip install google-generativeai
    ```

### **⚠️ 重要：关于Windows分页文件的说明**

这是一个对系统资源要求较高的脚本，尤其是在Windows系统上。

**每个进程大约需要 1GB 的分页文件（Windows虚拟内存）。**

这是因为每个独立的进程都需要加载Python解释器、相关库，并在处理PDF和调用API时占用相当大的内存。当物理内存不足时，操作系统会使用硬盘上的分页文件来作为临时内存。

**推荐配置：**
对于 `TARGET_TOTAL_CONCURRENCY = 40` 的默认设置，建议您至少拥有 **40GB** 的可用分页文件空间。如果您的分页文件过小，您可能会遇到 `[WinError 1455] 页面文件太小，无法完成操作` 的错误，导致进程创建失败。

您可以在Windows的“**查看高级系统设置**” -> “性能” -> “设置” -> “高级” -> “虚拟内存”中手动调整分页文件的大小。

## 使用方法

1.  **准备环境**:
    确保您已安装Python和`xelatex`，并运行 `pip install google-generativeai`。

2.  **文件结构**:
    请确保您的项目目录结构如下：
    ```
    /您的项目文件夹
    |-- run_script.py  (本脚本)
    |-- /结果2
        |-- 2022-1A_第1問_问题.pdf
        |-- /2022-1A_第1問_问题
        |   |-- /images
        |       |-- image1.jpg
        |-- ... (其他源文件和文件夹)
        |
        |-- /latex_output_final  (此目录会自动创建)
            |-- /2022-1A_第1問_问题
            |   |-- 2022-1A_第1問_问题.pdf (这是最终的成功标记！)
            |   |-- generated.pdf
            |   |-- generated.tex
            |   |-- /images
            |-- ... (其他任务的输出)
    ```

3.  **配置脚本**:
    打开脚本文件，修改 `--- 1. 全局配置 ---` 和 `--- 并发与调度配置 ---` 部分的参数，特别是 `API_KEYS` 列表。

4.  **运行脚本**:
    在您的终端中，导航到项目文件夹，然后运行：
    ```bash
    python run_script.py
    ```

## 理解终端输出

*   `🟢 绿色 [任务成功]`
    **含义**: 一路畅通！任务从头到尾完美完成。

*   `🟡 黄色 [任务失败 (函数返回False)]`
    **含义**: **可控失败**。程序没有崩溃，但在执行过程中遇到了一个已知的逻辑问题（最常见的是**LaTeX编译失败**）。**请查看此消息正上方的红色错误日志**来定位具体问题。此任务在下次运行时会被自动重试。

*   `🔴 红色 [发生严重异常]`
    **含义**: **严重车祸**！程序遇到了一个意料之外的错误（最常见的是**Google Gemini API调用失败或超时**）。此消息会打印出详细的异常信息。此任务在下次运行时也会被自动重试。

---
# 【新增】失败惩罚权重。这个值应该比较高，一次失败就应该让这个Key的优先级显著降低。

**作者**: [您可以在这里写上您的GitHub用户名]

**许可**: MIT License
